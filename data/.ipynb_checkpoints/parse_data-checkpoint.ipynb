{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow-gpu 1.10.0, python 2.7\n",
    "#theano for generating sequence weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re\n",
    "from helper_tools import *\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amino acid dictionary\n",
    "ORDER_KEY = \"XILVAGMFYWEDQNHCRKSTPBZ-\"[::-1]\n",
    "ORDER_LIST = list(ORDER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pdataframe_from_alignment_file(\"./GAL4_YEAST_1_b0.6.a2m\")\n",
    "print(\"number of data points:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of sequence:\", len(data.iloc[0][\"sequence\"]))\n",
    "print(\"sample sequence:\", data.iloc[0][\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indices that align (at least 50% of sequences are not gaps)\n",
    "indices = index_of_non_lower_case_dot(data.iloc[0][\"sequence\"])\n",
    "#Drop columns that are not part of the alignment\n",
    "data[\"seq\"] = list(map(prune_seq, data[\"sequence\"]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"pruned sequence length:\", len(data.iloc[0][\"seq\"]))\n",
    "PRUNED_SEQ_LENGTH = len(data.iloc[0][\"seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do this to reduce memory load\n",
    "del data[\"sequence\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aa = {0:'-', 1:'P', 2:'T', 3:'S', 4:'K', 5:'R', 6:'C', 7:'H', 8:'N', 9:'Q', \n",
    "           10:'D', 11:'E', 12:'W', 13:'Y', 14:'F', 15:'M', 16:'G', 17:'A', 18:'V', \n",
    "           19:'L', 20:'I', 21:'Z', 22:'B', 23:'X'}\n",
    "reverse_dict_aa = dict(map(reversed, dict_aa.items()))\n",
    "\n",
    "def translate_string_to_int(sequence):\n",
    "    out=[]\n",
    "    for i in sequence:\n",
    "         out.append(reverse_dict_aa[i])\n",
    "    return out\n",
    "\n",
    "data_aa = []\n",
    "for i, row in data.iterrows():\n",
    "    data_aa.append(translate_string_to_int(row[\"seq\"]))   \n",
    "    \n",
    "data_aa = np.array(data_aa) #this will be our training data\n",
    "print(data_aa.shape)\n",
    "print(data_aa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also get one-hot encoded sequences for calculating sequence weights\n",
    "training_data_one_hot=[]\n",
    "for i, row in data.iterrows():\n",
    "    training_data_one_hot.append(translate_string_to_one_hot(row[\"seq\"],ORDER_LIST))\n",
    "print(len(training_data_one_hot))\n",
    "\n",
    "training_data = np.array([np.array(list(sample.T.flatten())) for sample in training_data_one_hot])\n",
    "print(training_data.shape)\n",
    "\n",
    "data_one_hot = training_data.reshape([len(training_data), PRUNED_SEQ_LENGTH, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sequence weights\n",
    "x_train = data_one_hot\n",
    "theta=0.2\n",
    "\n",
    "X = T.tensor3(\"x\")\n",
    "cutoff = T.scalar(\"theta\")\n",
    "X_flat = X.reshape((X.shape[0], X.shape[1] * X.shape[2]))\n",
    "N_list, updates = theano.map(lambda x: 1.0 / T.sum(T.dot(X_flat, x) / T.dot(x, x) > 1 - cutoff), X_flat)\n",
    "weightfun = theano.function(inputs=[X, cutoff], outputs=[N_list],allow_input_downcast=True)\n",
    "\n",
    "weights = weightfun(x_train, theta)[0]\n",
    "np.save('weights.npy', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load test data (experimental data)\n",
    "exp_data_full = pd.read_csv(\"GAL4.csv\", sep=\",\", comment=\"#\")\n",
    "print(\"number of mutants:\", len(exp_data_full))\n",
    "exp_data_full.head(10) #\"linear\" column is the experimental data\n",
    "#print(exp_data_full.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deciding offset requires investigating the dataset and alignment.\n",
    "OFFSET=1  #6-5\n",
    "#where the first mutant position is 6 and first value of indices is 5\n",
    "#indices: indices that aligned in the training data. see above\n",
    "\n",
    "exp_data = pd.DataFrame(columns=exp_data_full.columns)\n",
    "#restrict test data to the subset of exp_data that we have aligned columns for\n",
    "#decide starting index depending on how the file is \"headered\"\n",
    "for i,row in exp_data_full[0:].iterrows():\n",
    "        pos = re.split(r'(\\d+)', row.mutant) \n",
    "        if int(pos[1]) - OFFSET in indices: \n",
    "            exp_data = exp_data.append(row)\n",
    "exp_data = exp_data.reset_index()\n",
    "target_values = list(exp_data[\"SEL_C_64h\"])\n",
    "print(len(target_values))\n",
    "print(exp_data.head(5))\n",
    "print(exp_data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_data = [re.split(r'(\\d+)', s) for s in exp_data.mutant]\n",
    "print(mutation_data[0:3])\n",
    "wt_sequence = data.iloc[0].seq #first sequence in alignment data\n",
    "print(wt_sequence)\n",
    "mutants = mutate_single(wt_sequence, mutation_data, offset=0, index=0) \n",
    "print(np.shape(mutants)) #list of mutant sequences\n",
    "\n",
    "#sanity checks\n",
    "print(len(mutants),len(exp_data))\n",
    "#check if mutant sequences are correct.\n",
    "print(list(zip(wt_sequence,mutants[0]))[:10])\n",
    "print(list(zip(wt_sequence,mutants[1103]))[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_aa = []\n",
    "for seq in mutants:\n",
    "    seq = \"\".join(seq)\n",
    "    test_data_aa.append(translate_string_to_int(seq))\n",
    "    \n",
    "test_data_aa = np.array(test_data_aa) #this will be our training data\n",
    "print(test_data_aa.shape)\n",
    "print(test_data_aa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_aa', data_aa)\n",
    "np.save('test_data_aa', test_data_aa)\n",
    "np.save('target_values', target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
